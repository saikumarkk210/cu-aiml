{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector\n",
    "### Author: Saikumar Kalyankrishnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.079913200Z",
     "start_time": "2024-02-21T19:06:13.009854900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located at [https://static.bc-edx.com/mbc/ai/m4/datasets/spam-data.csv](https://static.bc-edx.com/mbc/ai/m4/datasets/spam-data.csv)\n",
    "\n",
    "Dataset Source: [UCI Machine Learning Library](https://archive-beta.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "Import the data using Pandas. Display the resulting DataFrame to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.667871500Z",
     "start_time": "2024-02-21T19:06:13.015183500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.00               0.64           0.64           0.0   \n1            0.21               0.28           0.50           0.0   \n2            0.06               0.00           0.71           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n3           0.63            0.00              0.31                0.63   \n4           0.63            0.00              0.31                0.63   \n\n   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n0             0.00            0.00  ...         0.00        0.000   \n1             0.00            0.94  ...         0.00        0.132   \n2             0.64            0.25  ...         0.01        0.143   \n3             0.31            0.63  ...         0.00        0.137   \n4             0.31            0.63  ...         0.00        0.135   \n\n   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0          0.0        0.778        0.000        0.000   \n1          0.0        0.372        0.180        0.048   \n2          0.0        0.276        0.184        0.010   \n3          0.0        0.137        0.000        0.000   \n4          0.0        0.135        0.000        0.000   \n\n   capital_run_length_average  capital_run_length_longest  \\\n0                       3.756                          61   \n1                       5.114                         101   \n2                       9.821                         485   \n3                       3.537                          40   \n4                       3.537                          40   \n\n   capital_run_length_total  spam  \n0                       278     1  \n1                      1028     1  \n2                      2259     1  \n3                       191     1  \n4                       191     1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"http://static.bc-edx.com/mbc/ai/m4/datasets/spam-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
    "\n",
    "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellow' size='4'>*_I believe Random Forest Model would perform better than Logistic Regression as it makes predictions based on random decision trees.\n",
    "This prevents overfitting and provides a more accurate prediction especially with imbalanced data not being prone to biased decisions.\n",
    "Random Forest Model can manage non-linear correlations between features and the label.\n",
    "Run efficiently on large datasets._*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.673089800Z",
     "start_time": "2024-02-21T19:06:13.673089800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the labels set `y` and features DataFrame `X`\n",
    "# Import Module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split training and testing sets\n",
    "# Create the features DataFrame, X\n",
    "X = data.copy()\n",
    "X = X.drop(columns='spam')\n",
    "\n",
    "# Create the target set `y`\n",
    "y = data['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.686524100Z",
     "start_time": "2024-02-21T19:06:13.677761500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "spam\n0    2788\n1    1813\nName: count, dtype: int64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of the labels variable (`y`) by using the `value_counts` function.\n",
    "# Check the number of Spam vs. Non-Spam ('spam') using value_counts\n",
    "# 1: Spam | 0: Non-Spam\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.746044800Z",
     "start_time": "2024-02-21T19:06:13.686524100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n1617            0.00               0.00           0.00           0.0   \n419             0.51               0.43           0.29           0.0   \n2378            0.00               0.00           1.46           0.0   \n1925            0.00               0.00           0.00           0.0   \n455             0.00               0.00           0.71           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n1617           0.23            0.00              0.00                0.00   \n419            0.14            0.03              0.00                0.18   \n2378           0.00            0.00              0.00                0.00   \n1925           0.00            0.00              0.00                1.78   \n455            0.17            0.00              0.35                0.35   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n1617             0.00            0.00  ...                  0.11        0.000   \n419              0.54            0.62  ...                  0.00        0.012   \n2378             0.00            0.00  ...                  0.00        0.471   \n1925             0.00            0.00  ...                  0.00        0.000   \n455              0.00            0.17  ...                  0.00        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n1617        0.381          0.0        0.016        0.000        0.000   \n419         0.078          0.0        0.443        0.510        0.133   \n2378        0.550          0.0        0.078        0.000        0.000   \n1925        0.000          0.0        0.000        0.000        0.000   \n455         0.057          0.0        0.057        0.171        0.000   \n\n      capital_run_length_average  capital_run_length_longest  \\\n1617                       2.470                          41   \n419                        6.590                         739   \n2378                       2.552                          16   \n1925                       1.666                           7   \n455                        1.974                          34   \n\n      capital_run_length_total  \n1617                       504  \n419                       2333  \n2378                       171  \n1925                        15  \n455                        229  \n\n[5 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1617</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.23</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.11</td>\n      <td>0.000</td>\n      <td>0.381</td>\n      <td>0.0</td>\n      <td>0.016</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.470</td>\n      <td>41</td>\n      <td>504</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>0.51</td>\n      <td>0.43</td>\n      <td>0.29</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.18</td>\n      <td>0.54</td>\n      <td>0.62</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.012</td>\n      <td>0.078</td>\n      <td>0.0</td>\n      <td>0.443</td>\n      <td>0.510</td>\n      <td>0.133</td>\n      <td>6.590</td>\n      <td>739</td>\n      <td>2333</td>\n    </tr>\n    <tr>\n      <th>2378</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.46</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.471</td>\n      <td>0.550</td>\n      <td>0.0</td>\n      <td>0.078</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.552</td>\n      <td>16</td>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>1925</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.78</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.666</td>\n      <td>7</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>455</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>0.17</td>\n      <td>0.00</td>\n      <td>0.35</td>\n      <td>0.35</td>\n      <td>0.00</td>\n      <td>0.17</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.057</td>\n      <td>0.0</td>\n      <td>0.057</td>\n      <td>0.171</td>\n      <td>0.000</td>\n      <td>1.974</td>\n      <td>34</td>\n      <td>229</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 57 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "1617    1\n419     1\n2378    0\n1925    0\n455     1\nName: spam, dtype: int64"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the y_train DataFrame\n",
    "y_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.780441300Z",
     "start_time": "2024-02-21T19:06:13.708867600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `StandardScaler` to scale the features' data. Remember that only `X_train` and `X_test` DataFrames should be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.817989200Z",
     "start_time": "2024-02-21T19:06:13.715943100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "StandardScaler()",
      "text/html": "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.817989200Z",
     "start_time": "2024-02-21T19:06:13.730806700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.817989200Z",
     "start_time": "2024-02-21T19:06:13.739607200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Logistic Regression Model\n",
    "\n",
    "Create a Logistic Regression model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.847126200Z",
     "start_time": "2024-02-21T19:06:13.746044800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9278260869565217\n",
      "Testing Data Score: 0.9244135534317984\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a `LogisticRegression` function and assign it to a variable named `logistic_regression_model`.\n",
    "logistic_regression_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "logistic_regression_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Training Data Score: {logistic_regression_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.847126200Z",
     "start_time": "2024-02-21T19:06:13.780441300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "testing_predictions = logistic_regression_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the predictions\n",
    "testing_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "      Testing Data Predictions  Testing Data Actual Targets\n893                          0                            1\n2279                         0                            0\n3691                         0                            0\n4256                         0                            0\n3968                         0                            0\n...                        ...                          ...\n1169                         1                            1\n2769                         0                            0\n1710                         0                            1\n1459                         1                            1\n4577                         0                            0\n\n[1151 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Testing Data Predictions</th>\n      <th>Testing Data Actual Targets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>893</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2279</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3691</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4256</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3968</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1169</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2769</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1710</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4577</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1151 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save both the test predictions and actual test values to a DataFrame\n",
    "results_data = pd.DataFrame({\n",
    "    \"Testing Data Predictions\": testing_predictions, \n",
    "    \"Testing Data Actual Targets\": y_test})\n",
    "\n",
    "results_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.847126200Z",
     "start_time": "2024-02-21T19:06:13.787233800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:13.847126200Z",
     "start_time": "2024-02-21T19:06:13.798104200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression Model with Scaled Data: 0.9244135534317984\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9244135534317984"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the model's accuracy on the test dataset\n",
    "acc_score = accuracy_score(y_test, testing_predictions)\n",
    "\n",
    "print(f\"Accuracy for Logistic Regression Model with Scaled Data: {acc_score}\")\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create and Fit a Logistic Regression Model with Non-Scaled Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9295652173913044\n",
      "Testing Data Score: 0.9261511728931364\n",
      "Accuracy for Logistic Regression Model without Scaled Data: 0.5030408340573415\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5030408340573415"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a `LogisticRegression` function and assign it to a variable named `logistic_regression_model`.\n",
    "logistic_regression_non_scaled = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Fit the model\n",
    "logistic_regression_non_scaled.fit(X_train.values, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Training Data Score: {logistic_regression_non_scaled.score(X_train.values, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_non_scaled.score(X_test.values, y_test)}\")\n",
    "\n",
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "testing_predictions_non_scaled = logistic_regression_model.predict(X_test.values)\n",
    "\n",
    "# Calculate the model's accuracy on the test dataset\n",
    "acc_score = accuracy_score(y_test, testing_predictions_non_scaled)\n",
    "\n",
    "print(f\"Accuracy for Logistic Regression Model without Scaled Data: {acc_score}\")\n",
    "acc_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:14.611555100Z",
     "start_time": "2024-02-21T19:06:13.802208200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Random Forest Classifier Model\n",
    "\n",
    "Create a Random Forest Classifier model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:15.521557200Z",
     "start_time": "2024-02-21T19:06:14.611555100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=1, criterion='entropy')\n",
    "\n",
    "# Fit the model\n",
    "rf_model = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:15.543926500Z",
     "start_time": "2024-02-21T19:06:15.521557200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 1, 1, 0], dtype=int64)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved Random Forest Classifier model using the test data\n",
    "testing_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Review the predictions\n",
    "testing_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:15.548971Z",
     "start_time": "2024-02-21T19:06:15.543926500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifier Model without Scaled Data: 0.9574283231972198\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9574283231972198"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "acc_score = accuracy_score(y_test, testing_predictions)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy for Random Forest Classifier Model without Scaled Data: {acc_score}\")\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.10862296291345132, 'char_freq_!'),\n (0.08502471094582552, 'char_freq_$'),\n (0.07084893700258087, 'capital_run_length_average'),\n (0.07066424603146788, 'word_freq_remove'),\n (0.06334277292805543, 'capital_run_length_longest'),\n (0.05205276070762099, 'word_freq_hp'),\n (0.04901741863213349, 'word_freq_free'),\n (0.04684202268029729, 'capital_run_length_total'),\n (0.04179646948577686, 'word_freq_your'),\n (0.03247748216789178, 'word_freq_money')]"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature importance array\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# List the top 10 most important features\n",
    "importances_sorted = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "importances_sorted[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:15.581334500Z",
     "start_time": "2024-02-21T19:06:15.548971Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create and Fit a Random Forest Classifier Model with Scaled Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 1, 1, 0], dtype=int64)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score for scaled data\n",
    "rf_scaled = RandomForestClassifier(n_estimators=128, random_state=1, criterion='entropy')\n",
    "\n",
    "# Fit the model\n",
    "rf_scaled = rf_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make and save testing predictions with the saved Random Forest Classifier model using the test data\n",
    "testing_predictions_scaled = rf_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Review the predictions for scaled data\n",
    "testing_predictions_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:16.532288600Z",
     "start_time": "2024-02-21T19:06:15.563146600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifier Model with Scaled Data: 0.9582971329278888\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9582971329278888"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions_scaled`.\n",
    "acc_score = accuracy_score(y_test, testing_predictions_scaled)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy for Random Forest Classifier Model with Scaled Data: {acc_score}\")\n",
    "acc_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:16.539738300Z",
     "start_time": "2024-02-21T19:06:16.534550500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Models\n",
    "\n",
    "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the following markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='yellow' size='4'>As predicted, Random Forest model did perform better than Logistic Regression, but a few observations spiked my curiosity.\n",
    "1.The factor of `random_state`: the value did have an effect on the accuracy for both the models\n",
    "2.The `n_estimators` also had an effect on the accuracy of Random Forest model along with the parameter `criterion` (`criterion=entropy` had the maximum accuracy)\n",
    "3.Is scaling recommended in this case where the accuracy isn't improving too much?<br>\n",
    "The challenge would be to find the perfect combination of `random_state`, `n_estimators` and `criterion` to improve the accuracy of the model.</font>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Logistic Regression Model: Observations\n",
    "\n",
    "| random_state | scaled |                   accuracy                    |\n",
    "|:------------:|:------:|:---------------------------------------------:|\n",
    "|      78      |   Y    | <font color='green'>0.9278887923544744</font> |\n",
    "|      99      |   Y    |              0.9244135534317984               |\n",
    "|     151      |   Y    |              0.9226759339704604               |\n",
    "|      56      |   Y    |              0.9244135534317984               |\n",
    "|   default    |   Y    |              0.9261511728931364               |\n",
    "|   default    |   N    |              0.5030408340573415               |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Random Forest Classifier Model: Observations\n",
    "| random_state | scaled |                   accuracy                    |\n",
    "|:------------:|:------:|:---------------------------------------------:|\n",
    "|      1       |   N    |              0.9574283231972198               |\n",
    "|      1       |   Y    | <font color='green'>0.9582971329278888</font> |\n",
    "<br>\n",
    "\n",
    "| n_estimators |                   accuracy                    |\n",
    "|:------------:|:---------------------------------------------:|\n",
    "|     128      | <font color='green'>0.9600347523892268</font> |\n",
    "|      64      |              0.9591659426585578               |\n",
    "|   default    |              0.9565595134665508               |\n",
    "<br>\n",
    "\n",
    "| criterion |                   accuracy                    |\n",
    "|:---------:|:---------------------------------------------:|\n",
    "|  entropy  | <font color='green'>0.9600347523892268</font> |\n",
    "|   gini    |              0.9556907037358818               |\n",
    "| log_loss  |              0.9548218940052129               |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
